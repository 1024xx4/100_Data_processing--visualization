{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 特殊な加工・可視化を行なう10本 Knock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 大容量CSV data を扱ってみよう\n",
    "容量無制限に処理できるものではない為、Memory容量との兼ね合いなどを考慮しつつ工夫する必要がでてくる、\n",
    "\n",
    "※時系列Data を大容量Data と仮定して使用し演習を実施。Data が小さくても Code の書き方と結果を確認し Image を掴む。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        id  place             receive_time  sensor_num  in1  out1  state1  \\\n0        0      1  2021-01-15 09:00:00.144           2  508    73       0   \n1        1      1  2021-01-15 09:00:01.146           2  508    73       0   \n2        2      1  2021-01-15 09:00:02.161           2  508    73       0   \n3        3      1  2021-01-15 09:00:03.176           2  508    73       0   \n4        4      1  2021-01-15 09:00:04.192           2  508    73       0   \n...    ...    ...                      ...         ...  ...   ...     ...   \n3535  3535      1  2021-01-15 09:59:55.054           2  782   156       0   \n3536  3536      1   2021-01-15 09:59:56.07           2  782   156       0   \n3537  3537      1  2021-01-15 09:59:57.085           2  782   156       0   \n3538  3538      1  2021-01-15 09:59:58.101           2  782   156       0   \n3539  3539      1  2021-01-15 09:59:59.116           2  782   156       0   \n\n      in2  out2  state2  \n0      73   508       0  \n1      73   508       0  \n2      73   508       0  \n3      73   508       0  \n4      73   508       0  \n...   ...   ...     ...  \n3535  156   782       0  \n3536  156   782       0  \n3537  156   782       0  \n3538  156   782       0  \n3539  156   782       0  \n\n[3540 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>place</th>\n      <th>receive_time</th>\n      <th>sensor_num</th>\n      <th>in1</th>\n      <th>out1</th>\n      <th>state1</th>\n      <th>in2</th>\n      <th>out2</th>\n      <th>state2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:00.144</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:01.146</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:02.161</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:03.176</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:04.192</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>3535</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:55.054</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>3536</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:56.07</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>3537</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:57.085</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>3538</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:58.101</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>3539</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:59.116</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3540 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File を読み込む\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/chapter8/person_count_out_0001_2021011509.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "仮に Data数が 100万~1000万以上の Data になると pandas.read_csv() で一括で読み込もうとすると OOM Error で Program が落ちると想定される。\n",
    "※ OOM Error: Memory不足による Error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 10)\n",
      "(512, 10)\n",
      "(512, 10)\n",
      "(512, 10)\n",
      "(512, 10)\n",
      "(512, 10)\n",
      "(468, 10)\n"
     ]
    }
   ],
   "source": [
    "# OOM Error を回避する為に引数で桁数を指定して読み込む\n",
    "for df in pd.read_csv('data/chapter8/person_count_out_0001_2021011509.csv', chunksize=512):\n",
    "    print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`chunksize=` 明示的に指定すると指定した行数ごとに CSV File を読み込む"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 読み込んだ Dataに対して何らかの処理を行なった上で、別File に保存してみる\n",
    "i = 0\n",
    "for df in pd.read_csv('data/chapter8/person_count_out_0001_2021011509.csv', chunksize=64):  # Chunksize を指定して読み込み\n",
    "    df['processed_per_chunk'] = True  # column を追加\n",
    "    df.to_csv('data/chapter8/processed_big_data.csv', mode='a', index_label=False, header=i == 0)  # 新しい File に保存していく\n",
    "    # media='a' と指定することで同じ File に対して追記して保存する。（※'a': append の頭文字）\n",
    "    # header=i == 0 とすることで i == 0 の時だけ header ありで出力するようにしている\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        id place             receive_time sensor_num  in1 out1 state1  in2  \\\n0        0     1  2021-01-15 09:00:00.144          2  508   73      0   73   \n1        1     1  2021-01-15 09:00:01.146          2  508   73      0   73   \n2        2     1  2021-01-15 09:00:02.161          2  508   73      0   73   \n3        3     1  2021-01-15 09:00:03.176          2  508   73      0   73   \n4        4     1  2021-01-15 09:00:04.192          2  508   73      0   73   \n...    ...   ...                      ...        ...  ...  ...    ...  ...   \n3535  3535     1  2021-01-15 09:59:55.054          2  782  156      0  156   \n3536  3536     1   2021-01-15 09:59:56.07          2  782  156      0  156   \n3537  3537     1  2021-01-15 09:59:57.085          2  782  156      0  156   \n3538  3538     1  2021-01-15 09:59:58.101          2  782  156      0  156   \n3539  3539     1  2021-01-15 09:59:59.116          2  782  156      0  156   \n\n     out2 state2 processed_per_chunk  \n0     508      0                True  \n1     508      0                True  \n2     508      0                True  \n3     508      0                True  \n4     508      0                True  \n...   ...    ...                 ...  \n3535  782      0                True  \n3536  782      0                True  \n3537  782      0                True  \n3538  782      0                True  \n3539  782      0                True  \n\n[14163 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>place</th>\n      <th>receive_time</th>\n      <th>sensor_num</th>\n      <th>in1</th>\n      <th>out1</th>\n      <th>state1</th>\n      <th>in2</th>\n      <th>out2</th>\n      <th>state2</th>\n      <th>processed_per_chunk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:00.144</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:01.146</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:02.161</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:03.176</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2021-01-15 09:00:04.192</td>\n      <td>2</td>\n      <td>508</td>\n      <td>73</td>\n      <td>0</td>\n      <td>73</td>\n      <td>508</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>3535</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:55.054</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>3536</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:56.07</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>3537</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:57.085</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>3538</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:58.101</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>3539</td>\n      <td>1</td>\n      <td>2021-01-15 09:59:59.116</td>\n      <td>2</td>\n      <td>782</td>\n      <td>156</td>\n      <td>0</td>\n      <td>156</td>\n      <td>782</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>14163 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 結果の確認\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv('data/chapter8/processed_big_data.csv')\n",
    "display(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## JSON 形式の File を扱ってみよう"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  value\n0   1      1\n1   2     10\n2   3    100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/chapter8/column_oriented.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":{\"0\":1,\"1\":2,\"2\":3},\"value\":{\"0\":1,\"1\":10,\"2\":100}}\n"
     ]
    }
   ],
   "source": [
    "# Pandas で読み込む前の状態を確認\n",
    "!type data\\chapter8\\column_oriented.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "列指向の JSON File という"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\":{\"id\":1,\"value\":1},\"1\":{\"id\":2,\"value\":10},\"2\":{\"id\":3,\"value\":100}}\n"
     ]
    }
   ],
   "source": [
    "!type data\\chapter8\\index_oriented.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Index指向の JSON File である"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       0   1    2\nid     1   2    3\nvalue  1  10  100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>value</th>\n      <td>1</td>\n      <td>10</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/chapter8/index_oriented.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "縦横が逆になっている"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  value\n0   1      1\n1   2     10\n2   3    100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/chapter8/index_oriented.json', orient='index')\n",
    "# 引数 orient='index' を指定することで Index指向のJSON File が正しく読み込める"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"schema\":{\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"id\",\"type\":\"integer\"},{\"name\":\"value\",\"type\":\"integer\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"},\"data\":[{\"index\":0,\"id\":1,\"value\":1},{\"index\":1,\"id\":2,\"value\":10},{\"index\":2,\"id\":3,\"value\":100}]}\n"
     ]
    }
   ],
   "source": [
    "# Table 指向な構造の JSON File（※ RDB の File を JSON File に dump する際に見られる構造）\n",
    "!type data\\chapter8\\table_oriented.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# そのまま Pandas で読み込んでみる\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/chapter8/table_oriented.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001B[0m, in \u001B[0;36mread_json\u001B[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001B[0m\n\u001B[0;32m    609\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m json_reader:\n\u001B[1;32m--> 612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:746\u001B[0m, in \u001B[0;36mJsonReader.read\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    744\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_object_parser(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_lines(data_lines))\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 746\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001B[0m, in \u001B[0;36mJsonReader._get_object_parser\u001B[1;34m(self, json)\u001B[0m\n\u001B[0;32m    766\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 768\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseries\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    771\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, \u001B[38;5;28mbool\u001B[39m):\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001B[0m, in \u001B[0;36mParser.parse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    878\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_numpy()\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 880\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_no_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    883\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:1132\u001B[0m, in \u001B[0;36mFrameParser._parse_no_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1129\u001B[0m orient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morient\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;241m=\u001B[39m \u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m   1134\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1136\u001B[0m     decoded \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;28mstr\u001B[39m(k): v\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m loads(json, precise_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecise_float)\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1139\u001B[0m     }\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:636\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    630\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[0;32m    631\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    632\u001B[0m     )\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    635\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[1;32m--> 636\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[0;32m    638\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmrecords\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmrecords\u001B[39;00m\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    494\u001B[0m     arrays \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    495\u001B[0m         x\n\u001B[0;32m    496\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x\u001B[38;5;241m.\u001B[39mdtype, ExtensionDtype)\n\u001B[0;32m    497\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m x\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m    498\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays\n\u001B[0;32m    499\u001B[0m     ]\n\u001B[0;32m    500\u001B[0m     \u001B[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001B[39;00m\n\u001B[1;32m--> 502\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 120\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[1;32m~\\dsLab\\100_Data_processing-visualization\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001B[0m, in \u001B[0;36m_extract_index\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    674\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll arrays must be of the same length\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    676\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_dicts:\n\u001B[1;32m--> 677\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    678\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    679\u001B[0m     )\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_series:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# for mypy\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "# そのまま Pandas で読み込んでみる\n",
    "pd.read_json('data/chapter8/table_oriented.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Error になる"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  value\n0   1      1\n1   2     10\n2   3    100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/chapter8/table_oriented.json', orient='table')\n",
    "# 引数 orient='table' を指定することで Table指向の JSON File も読み込める"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "JSON 形式には様々な構造が存在するため、読み込む際は注意が必要。\n",
    "※今回の演習で登場した構造以外にも pandas.read_json() で読み込める構造がある。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Web からの Data を取得してみよう\n",
    "Web site に対して Request を http送信した際、Server が Client に結果を送信する Case では、JSON形式が使われる場合が多い。\n",
    "上記の Case の場合の Data の扱う"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "b'{\"abbreviation\":\"JST\",\"client_ip\":\"60.71.122.177\",\"datetime\":\"2022-06-11T07:31:27.342018+09:00\",\"day_of_week\":6,\"day_of_year\":162,\"dst\":false,\"dst_from\":null,\"dst_offset\":0,\"dst_until\":null,\"raw_offset\":32400,\"timezone\":\"Asia/Tokyo\",\"unixtime\":1654900287,\"utc_datetime\":\"2022-06-10T22:31:27.342018+00:00\",\"utc_offset\":\"+09:00\",\"week_number\":23}'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worldtimeapi.org という Site に http request を送信し、東京の時刻等の情報を取得して、Contents を表示する\n",
    "import requests  # http request を扱う Package として requests を選択\n",
    "\n",
    "response = requests.get('https://worldtimeapi.org/api/timezone/Asia/Tokyo')\n",
    "response.content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Response が JSON形式の Data であることを確認。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'abbreviation': 'JST',\n 'client_ip': '60.71.122.177',\n 'datetime': '2022-06-11T07:31:27.342018+09:00',\n 'day_of_week': 6,\n 'day_of_year': 162,\n 'dst': False,\n 'dst_from': None,\n 'dst_offset': 0,\n 'dst_until': None,\n 'raw_offset': 32400,\n 'timezone': 'Asia/Tokyo',\n 'unixtime': 1654900287,\n 'utc_datetime': '2022-06-10T22:31:27.342018+00:00',\n 'utc_offset': '+09:00',\n 'week_number': 23}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSONのままでは扱いずらいため dict型に変換\n",
    "result = response.json()  # Response.json() で dict型に変換可能\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Key と値の関係について視認性が向上した。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "abbreviation                                 JST\nclient_ip                          60.71.122.177\ndatetime        2022-06-11T07:31:27.342018+09:00\nday_of_week                                    6\nday_of_year                                  162\ndst                                        False\ndst_from                                    None\ndst_offset                                     0\ndst_until                                   None\nraw_offset                                 32400\ntimezone                              Asia/Tokyo\nunixtime                              1654900287\nutc_datetime    2022-06-10T22:31:27.342018+00:00\nutc_offset                                +09:00\nweek_number                                   23\ndtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas.Series に変換してみる\n",
    "pd.Series(result)  # Pandas.Series() に引数を渡すことで Series に変換"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# 取得結果を保存しておく\n",
    "import json  # Json Libray を import\n",
    "\n",
    "with open('dump/response.json', mode='w') as f:  # with open に出力File 名を記載して mode='w'(書き込みMode)で Open.\n",
    "    json.dump(result, f)  # Json.dump() で File に内容を書き込み"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 定期的に Request を実行し、結果を１つの File に追記する\n",
    "import time  # time Library を import\n",
    "\n",
    "for _ in range(4):  # renge(4)で４回繰り返し処理\n",
    "    response = requests.get('https://worldtimeapi.org/api/timezone/Asia/Tokyo')\n",
    "    with open('dump/response.txt', mode='a') as f:  # mode='a' で追記Mode で File を Open\n",
    "        res = response.json()  # 変数に response を Response.json() で dict型で格納\n",
    "        f.write(f\"{json.dumps(res)}\\n\")  # File に変数に格納した Data を出力していく\n",
    "    time.sleep(1)  # １秒置く"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"abbreviation\": \"JST\", \"client_ip\": \"121.119.11.5\", \"datetime\": \"2022-06-08T15:38:48.264271+09:00\", \"day_of_week\": 3, \"day_of_year\": 159, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654670328, \"utc_datetime\": \"2022-06-08T06:38:48.264271+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"121.119.11.5\", \"datetime\": \"2022-06-08T15:38:49.319286+09:00\", \"day_of_week\": 3, \"day_of_year\": 159, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654670329, \"utc_datetime\": \"2022-06-08T06:38:49.319286+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"121.119.11.5\", \"datetime\": \"2022-06-08T15:38:50.398317+09:00\", \"day_of_week\": 3, \"day_of_year\": 159, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654670330, \"utc_datetime\": \"2022-06-08T06:38:50.398317+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"121.119.11.5\", \"datetime\": \"2022-06-08T15:38:51.462419+09:00\", \"day_of_week\": 3, \"day_of_year\": 159, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654670331, \"utc_datetime\": \"2022-06-08T06:38:51.462419+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"60.71.122.177\", \"datetime\": \"2022-06-11T07:31:32.813768+09:00\", \"day_of_week\": 6, \"day_of_year\": 162, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654900292, \"utc_datetime\": \"2022-06-10T22:31:32.813768+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"60.71.122.177\", \"datetime\": \"2022-06-11T07:31:34.042318+09:00\", \"day_of_week\": 6, \"day_of_year\": 162, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654900294, \"utc_datetime\": \"2022-06-10T22:31:34.042318+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"60.71.122.177\", \"datetime\": \"2022-06-11T07:31:35.297815+09:00\", \"day_of_week\": 6, \"day_of_year\": 162, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654900295, \"utc_datetime\": \"2022-06-10T22:31:35.297815+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n",
      "{\"abbreviation\": \"JST\", \"client_ip\": \"60.71.122.177\", \"datetime\": \"2022-06-11T07:31:36.540539+09:00\", \"day_of_week\": 6, \"day_of_year\": 162, \"dst\": false, \"dst_from\": null, \"dst_offset\": 0, \"dst_until\": null, \"raw_offset\": 32400, \"timezone\": \"Asia/Tokyo\", \"unixtime\": 1654900296, \"utc_datetime\": \"2022-06-10T22:31:36.540539+00:00\", \"utc_offset\": \"+09:00\", \"week_number\": 23}\n"
     ]
    }
   ],
   "source": [
    "# 出力した Data を確認\n",
    "!type dump\\response.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config File を扱ってみよう"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  name: pseudo\n",
      "  path: data/images_by_py/\n",
      "use_gpu: true\n"
     ]
    }
   ],
   "source": [
    "# yaml File の中身を出力し構造を確認\n",
    "!type data\\chapter8\\config.yml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dataset': {'name': 'pseudo', 'path': 'data/images_by_py/'}, 'use_gpu': True}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File を読み込む\n",
    "import yaml  # PyYaml Libray を import（※ PyYaml Library を要 pipenv install）\n",
    "\n",
    "with open('data/chapter8/config.yml', mode='r') as f:  # with open で mode='r'(読み込みMode)で Open.\n",
    "    config = yaml.safe_load(f)  # yaml.safe_load() で Data を読み込み変数に格納\n",
    "config  # 変数を出力"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data を確認すると、Json形式で保持されいている。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu = true\n",
      "\n",
      "[dataset]\n",
      "name = \"pseudo\"\n",
      "path = \"data/images_by_py/\"\n"
     ]
    }
   ],
   "source": [
    "# toml File の構造を確認\n",
    "!type data\\chapter8\\config.toml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'use_gpu': True, 'dataset': {'name': 'pseudo', 'path': 'data/images_by_py/'}}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import toml  # toml Library を import ※ pipenv install toml 要必要\n",
    "\n",
    "with open('data/chapter8/config.toml', mode='r') as f:  # File を mode='r'(読み込み mode)で開く\n",
    "    config = toml.load(f)  # toml.load() 関数で内容を読み込み変数に格納\n",
    "\n",
    "config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Json 形式で Data が保持されていることを確認。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 動画File を音声File へ変換してみよう\n",
    "音声 Data を用意する手法のひとつとして、動画 File から音声 Data に変換してみる"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in dump/audio_by_py.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip  # moviepy Package から VideoFileClip を import ※要 pipenv install moviepy\n",
    "\n",
    "video_clip = VideoFileClip('data/chapter8/sample_video.mp4')  # 動画File から VideoFileClip data を作成し変数に格納\n",
    "video_clip.audio.write_audiofile(\n",
    "    'dump/audio_by_py.mp3')  # VideoFileClip.audio.write_audiofile() 関数で mp4形式の動画File から mp3 形式の音声File に変換して出力"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 動画Flie を画像File へ分割してみよう\n",
    "実用を考えて、動画File を複数の画像File に分割する処理を行なう。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:03<00:00, 102.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2  # 画像処理を行なう Library を import\n",
    "from tqdm import trange  # 処理時間を表示してくれる Library を import. ※ 処理時間が長くかかるような時はお薦め\n",
    "import os  # OS の操作を Python で扱う為の Library を import\n",
    "\n",
    "cap = cv2.VideoCapture('data/chapter8/sample_video.mp4')  # 動画File を読み込み変数に格納\n",
    "img_dir = 'dump/images_by_py'  # 処理の結果を出力して保存する為の Directory の Path を変数に格納\n",
    "os.makedirs(img_dir, exist_ok=1)  # 上記、Directory を作成。 exist_ok=1 で指定した　Directory が既設の場合でも Error をはかないように設定\n",
    "n = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 動画File の Frame数を取得し変数に格納\n",
    "\n",
    "for i in trange(n):  # Frame数で Loop処理。trange()で囲むことで進捗状況を可視化してくれる\n",
    "    success, img = cap.read()  # Frame単位で画像を読み込み\n",
    "    if not success:\n",
    "        continue  # 読み込みに失敗した場合は何もしないように指定\n",
    "    cv2.imwrite(f\"{img_dir}/{i:04}.png\", img)  # 読み込みに成功した時に、Frame番号４桁で設定し出力"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png', '0248.png', '0249.png', '0250.png', '0251.png', '0252.png', '0253.png', '0254.png', '0255.png', '0256.png', '0257.png', '0258.png', '0259.png', '0260.png', '0261.png', '0262.png', '0263.png', '0264.png', '0265.png', '0266.png', '0267.png', '0268.png', '0269.png', '0270.png', '0271.png', '0272.png', '0273.png', '0274.png', '0275.png', '0276.png', '0277.png', '0278.png', '0279.png', '0280.png', '0281.png', '0282.png', '0283.png', '0284.png', '0285.png', '0286.png', '0287.png', '0288.png', '0289.png', '0290.png', '0291.png', '0292.png', '0293.png', '0294.png', '0295.png', '0296.png', '0297.png', '0298.png', '0299.png', '0300.png', '0301.png', '0302.png', '0303.png', '0304.png', '0305.png', '0306.png', '0307.png', '0308.png', '0309.png', '0310.png', '0311.png', '0312.png', '0313.png', '0314.png', '0315.png', '0316.png', '0317.png', '0318.png', '0319.png', '0320.png', '0321.png', '0322.png', '0323.png', '0324.png', '0325.png', '0326.png', '0327.png', '0328.png', '0329.png', '0330.png', '0331.png', '0332.png', '0333.png', '0334.png', '0335.png', '0336.png', '0337.png', '0338.png', '0339.png', '0340.png', '0341.png', '0342.png', '0343.png', '0344.png', '0345.png', '0346.png', '0347.png', '0348.png', '0349.png', '0350.png', '0351.png', '0352.png', '0353.png', '0354.png', '0355.png', '0356.png', '0357.png', '0358.png', '0359.png', '0360.png', '0361.png', '0362.png', '0363.png', '0364.png', '0365.png', '0366.png', '0367.png', '0368.png', '0369.png', '0370.png', '0371.png', '0372.png', '0373.png', '0374.png', '0375.png', '0376.png', '0377.png', '0378.png', '0379.png', '0380.png', '0381.png', '0382.png', '0383.png', '0384.png', '0385.png', '0386.png', '0387.png', '0388.png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(img_dir))  # 出力結果を確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PowerPoint や Word File を読み込んでみよう\n",
    "Office は、身近な Data だが CPU data として取り扱うには Data品質が悪い。\n",
    "できるだけ取り扱いは控えるべきだが人間には取り扱いやすく利用率も高いため、Data資源として活用したい Needs は高い。\n",
    "活用には工夫が必要な Case が多い。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pptx  # PowerPoint を Python で扱うためのの Module を import. ※要 `pipenv install python-pptx`\n",
    "\n",
    "pptx_data = pptx.Presentation('data/chapter8/サンプル_PowerPoint.pptx')  # PowerPoint data を読み込み変数に格納\n",
    "len(pptx_data.slides)  # Slide の page数を確 ※ Presentation.slides で Page毎の情報を取得できる。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sld_0 = pptx_data.slides[0]  # １page目の Slide情報を読み込み変数に格納\n",
    "shp_sld_0 = sld_0.shapes  # Page にいくつ情報があるか読み込み表示\n",
    "len(shp_sld_0)  # Slide情報がいくつか確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サンプルテキスト Font 18\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(shp_sld_0[0].text)  # Slide 1 page目の１つ目の情報にある Text data を抽出\n",
    "print(shp_sld_0[0].has_text_frame)  # 上記の情報が Text data か真偽を確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['サンプルテキスト Font 18', 'サンプルテキスト\\nFont 28', 'サンプル', '２枚目サンプルテキスト Font 18', '２枚目サンプルテキスト\\nFont 28', '', '']\n"
     ]
    }
   ],
   "source": [
    "texts = []  # 空の list を準備する\n",
    "for slide in pptx_data.slides:  # Slide を Page毎に loop する\n",
    "    for shape in slide.shapes:  # 各Slide page から情報を抽出\n",
    "        if shape.has_text_frame:  # 対象の情報に Text は含まれているか判別\n",
    "            texts.append(shape.text)  # Text data であれば準備した list に追加\n",
    "print(texts)  # list を確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import docx  # Word を Python で扱ための Module を import ※ 要`pipenv install python-docx`\n",
    "\n",
    "docx_data = docx.Document('data/chapter8/サンプル_Word.docx')  # Word data を読み込み変数に格納\n",
    "len(docx_data.paragraphs)  # Word Data の Paragraph がいくつかるか確認。※ Word data は Paragraph という Data単位で取り扱う"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'これは、サンプルテキストです。そして、これが一つめの段落になっています。いろいろ読み込んでいきましょう。'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_data.paragraphs[0].text  # １行目の Text を確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['これは、サンプルテキストです。そして、これが一つめの段落になっています。いろいろ読み込んでいきましょう。', '続いて、これが二つ目の段落になっています。', 'これが三つめの段落です。']\n"
     ]
    }
   ],
   "source": [
    "texts = []  # 空の list を準備\n",
    "for paragraph in docx_data.paragraphs:  # Word data の Paragraphs を loop処理\n",
    "    texts.append(paragraph.text)  # list に Paragraph data を追加していく\n",
    "print(texts)  # list に追加された Data を確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}